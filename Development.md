# Week1

This week I primarily became familiar with OpenCV, my library of choice for this final project.  I spend a lot of time reading documentation and reading up on articles on hand detection.  I had to learn different possible useful image processing techniques before I could start working on the hand-tracking problem.  As far as coding, I put into practice a few image processing techniques such as adding a median blur and dilating the image.

# Week2

This week, with being a little more familiar with OpenCV, spent less time learning the library and a greater amount of time reading articles on how others have approached hand detection.  Some valuable information that I learned was about how HSV is more meaningful than RGB data for recognition tasks due to how shadows affect RGB values.  I also spent a large amount of this week trying to get OpenFrameworks to work.  In the end I did not get it to work and instead decided to start working on fleshing out the ideas I had by writing code and running it on the command line instead of OpenFrameworks, with the intent of porting it over at a later time.

As far as the programming, after giving up on OpenFrameworks for the time being, I became much more productive.  I learned about how HSV is more meaningful than RGB data and so I wrote a program utilizing OpenCV that gather the RGB values within a region of interest - a square that I got to appear on the screen with text above it.  I was able to demonstrate how the output to my terminal changed as I moved my red water bottle in and out of the region of interest.  I also created a histogram method that would find the average color data within a region of interest, but still needed to figure out how to collect this data overtime so that I could do calibration for a persons skin tone.

# Week3

This week I continued along the path of developing as much as possible without worrying about the mess of OpenFrameworks.  I greatly expanded on the previous week, going from gathering all of the RGB values within a region to taking those values, converting them to HSV, and finding their average.  I succesfully implemented an overtime gathering method that I discussed last week.  With this, the overall program I came up with went as follows.  I got a region of interest as well as instructions to appear on screen, mean color data would be calculated over a few hundred frames to figure out the skin tone of your hand.  After the hand color was calculated, everything else was to be set as background.  OpenCV has a nice function that sets everything not in a range of values to black.  I did a lot of testing to figure out what good values were to create a wide enough spread around the average hand data without being too wide.  With this, I essentially finished my handtracker with the only issue being that faces would be detected as well.  The goals for the next week are to fix this as well as to port my program into OF.

# Week4

This week was very brutal trying to put my handtracking ideas into OpenCV.  At first, I realized that certain things such as how I was receiving data from my camera would change from OpenCV to OF.  OF has its own methods and data structures that I needed to integrate with OpenCV, and unlike OpenCV, there was little to no documentation for the openFrameworks objects and methods I needed to use.  However, even though this was difficult, things only became worse.  I would frequently run into issues about trying to access variables that didn't exist even though there was no reason why they shouldn't.  I spent probably over 10 hours debugging or re-writing code in hopes that the issues would go away.   I then spent a few more hours reading OpenFrameworks forum posts only to discover that there were some bugs with using a camera on Mac that had only been fixed in an openFrameworks update just a few days earlier. 

While the frustrations above took up most of my time, I was luckily able to pull something together.  While it was frustrating that it took hours to do what should've been a copy and paste from the previous weeks, I did make some progress.  Because of difficulties with converting between OF and OpenCV data (the difficulty being copying this much data back and forth frequently is too expensive for a real time project) I had to come up with a new way to find contours.  Before I was creating a binary image using an ideal color range.  This week, I still use color to find contours, however, I then look at the biggest contours as well as the velocity of the contours.  The idea is that this can solve the issue of accidentally detecting faces as they are less likely to have a high enough velocity to be tracked.  I also came up with a method to take the difference between each frame, which does something similar in principal to what velocity does.  Doing my original contouring method on top of a frame that has differences stored should in theory complete my hand detection.  Because of how difficult openFrameworks was on various levels, I also came up with a pivot idea for my project this week because I ended up with a lot less actual development time than I thought.  The new idea is a type of first person "iron man" game where the x value of your hand is tracked and an image of an arm is placed at the bottom of the screen at that location.  You can then move the arm left and right while the arm shoots a laser every few seconds.  The goal is to hit blue boxes and avoid red boxes that will be randomly generated on the other side of the screen.
